{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "\n",
    "## Task 1\n",
    "\n",
    "Using the files in _rural.txt_ and _science.txt_ , train and test classifiers provided in scikit-learn. The goal of this task is that you explore different features, not only in the classifier, but also in the vectorizer:\n",
    "\n",
    "a) Each file (rural and science) contains senetnce-wise documents. Your job is to create a list of documents and their corresponding label (rural, science). This data structure (up to you which one you want to use) will be used later as input for your vectorizer. E.g. you can think about it as a table, which contains in the first column the sentences of both files and in the second column each class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PM denies knowledge of AWB kickbacks</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Prime Minister has denied he knew AWB was ...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Letters from John Howard and Deputy Prime Mini...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In one of the letters Mr Howard asks AWB manag...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Opposition's Gavan O'Connor says the lette...</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Liddicoat hopes this will one day make it poss...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>If you understand what they are then ... you m...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>An ancient ancestor of today's crocodiles look...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>The discovery of a six-foot-long, bipedal and ...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>The crocodile ancestor fossil, found in the ba...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1087 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  1\n",
       "0                 PM denies knowledge of AWB kickbacks  r\n",
       "1    The Prime Minister has denied he knew AWB was ...  r\n",
       "2    Letters from John Howard and Deputy Prime Mini...  r\n",
       "3    In one of the letters Mr Howard asks AWB manag...  r\n",
       "4    The Opposition's Gavan O'Connor says the lette...  r\n",
       "..                                                 ... ..\n",
       "592  Liddicoat hopes this will one day make it poss...  s\n",
       "593  If you understand what they are then ... you m...  s\n",
       "594  An ancient ancestor of today's crocodiles look...  s\n",
       "595  The discovery of a six-foot-long, bipedal and ...  s\n",
       "596  The crocodile ancestor fossil, found in the ba...  s\n",
       "\n",
       "[1087 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# read files into individual dataframes and add column for label (0 = science, 1 = rural)\n",
    "data_science = pd.read_csv(\"science.txt\", sep='\\t', header=None)\n",
    "data_science[1] = 's'\n",
    "data_rural = pd.read_csv(\"rural.txt\", sep='\\t', header=None)\n",
    "data_rural[1] = 'r'\n",
    "\n",
    "# combine dataframes \n",
    "data_total = data_rural.append(data_science)\n",
    "display(data_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Split the data into train (70%) and test (30%) sets and use the _tf-idf-vectorizer_ provided by scikit-learn and explained in class to train following classifiers provided also by scikit-learn: _naive_bayes.GaussianNB()_ and _svm.LinearSVC()_ . __Hint:__ Please notice that the Gaussian NB Classifier takes a dense matrix as input and the output of the vectorizer is a sparse matrix. Use *my_matrix.__toarray()__* for this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train, text_test, label_train, label_test = train_test_split(data_total[0], data_total[1], test_size=0.30, random_state=1234, shuffle=True)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(text_train)\n",
    "print(bow_matrix.toarray())\n",
    "bayes_classifier = naive_bayes.GaussianNB()\n",
    "bayes_classifier.fit(bow_matrix.toarray(), label_train)\n",
    "svm_classifier = svm.LinearSVC()\n",
    "svm_classifier.fit(bow_matrix, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Evaluate both classifiers using only the test set, report accuracy, recall, percision, and f-measure and explain differences in the performance if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes: \n",
      "\n",
      "Accuracy: 0.9296636085626911\n",
      "\n",
      "Percision Science: 0.9590643274853801\n",
      "Recall Science: 0.9111111111111111\n",
      "F-Measure Science: 0.9344729344729344\n",
      "\n",
      "Precision Rural: 0.8974358974358975\n",
      "Recall Rural: 0.9523809523809523\n",
      "F-Measure Rural: 0.924092409240924\n",
      "\n",
      "SVM: \n",
      "\n",
      "Accuracy: 0.9480122324159022\n",
      "\n",
      "Percision Science: 0.9267015706806283\n",
      "Recall Science: 0.9833333333333333\n",
      "F-Measure Science: 0.9541778975741241\n",
      "\n",
      "Precision Rural: 0.9779411764705882\n",
      "Recall Rural: 0.9047619047619048\n",
      "F-Measure Rural: 0.9399293286219081\n"
     ]
    }
   ],
   "source": [
    "test_data_matrix = vectorizer.transform(text_test)\n",
    "\n",
    "# test and evaluate Bayes classifier\n",
    "results_bayes = bayes_classifier.predict(test_data_matrix.toarray())\n",
    "correct_bayes = np.sum(np.equal(results_bayes, label_test))\n",
    "\n",
    "print(\"Bayes: \")\n",
    "print()\n",
    "print(\"Accuracy: \" + str(metrics.accuracy_score(label_test, results_bayes)))\n",
    "print()\n",
    "print(\"Percision Science: \" + str(metrics.precision_score(label_test, results_bayes, pos_label = 's')))\n",
    "print(\"Recall Science: \" + str(metrics.recall_score(label_test, results_bayes, pos_label = 's')))\n",
    "print(\"F-Measure Science: \" + str(metrics.f1_score(label_test, results_bayes, pos_label = 's')))\n",
    "print()\n",
    "print(\"Precision Rural: \" + str(metrics.precision_score(label_test, results_bayes, pos_label = 'r')))\n",
    "print(\"Recall Rural: \" + str(metrics.recall_score(label_test, results_bayes, pos_label = 'r')))\n",
    "print(\"F-Measure Rural: \" + str(metrics.f1_score(label_test, results_bayes, pos_label = 'r')))\n",
    "\n",
    "print()\n",
    "\n",
    "# test and evaluate SVM classifier\n",
    "results_svm = svm_classifier.predict(test_data_matrix.toarray())\n",
    "correct = np.sum(np.equal(results_svm, label_test))\n",
    "\n",
    "print(\"SVM: \")\n",
    "print()\n",
    "print(\"Accuracy: \" + str(metrics.accuracy_score(label_test, results_svm)))\n",
    "print()\n",
    "print(\"Percision Science: \" + str(metrics.precision_score(label_test, results_svm, pos_label = 's')))\n",
    "print(\"Recall Science: \" + str(metrics.recall_score(label_test, results_svm, pos_label = 's')))\n",
    "print(\"F-Measure Science: \" + str(metrics.f1_score(label_test, results_svm, pos_label = 's')))\n",
    "print()\n",
    "print(\"Precision Rural: \" + str(metrics.precision_score(label_test, results_svm, pos_label = 'r')))\n",
    "print(\"Recall Rural: \" + str(metrics.recall_score(label_test, results_svm, pos_label = 'r')))\n",
    "print(\"F-Measure Rural: \" + str(metrics.f1_score(label_test, results_svm, pos_label = 'r')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The svm.LinearSVC classifier scores better in every aspect except for the precision score on the science texts (~ 0.03 worse) and recall score on the rural texts (~ 0.05 worse). Overall however, the performance is fairly similar. Both classifiers have scores above 0.90 except for the rural percision of the naive Bayes classifier (0.897)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Using the same splits from __Task 1__:\n",
    "\n",
    "a) Use spaCy to extract vector representations of each document (sentence) in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Train again new instances of both classifiers but this time the input should be only the vector representations obtained from spaCy and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Report accuracy, recall, precision, and f-measure and explain differences to the results of __tf-idf__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
